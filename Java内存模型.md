---
description: Java memory model
---

# Java内存模型

Java线程之间的通信对程序员完全透明，内存可见性问题很容易困扰Java程序员。

## Java内存模型的基础

### 并发编程模型的两个关键问题

在并发编程中，需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的火丁实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制由两种：**共享内存**和**消息传递**。

在共享内存的并发模型里，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过发送消息来显式进行通信。

同步是指程序中用于控制不同线程间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。

Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。

### Java内存模型的抽象结构

在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享（我们在这里用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量，方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不会受内存模型的影响。

Java线程之间的通信由Java内存模型(简称JMM)控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本。本地内存式JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

如果线程A与线程B之间要通信的话，必须经历下面两个步骤：

- 线程A把本地内存A中更新过程的共享变量刷新到主内存中去。
- 线程B到主内存中去读取线程A之前已更新过的共享变量。

从整体上看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。

### 从源代码到指令序列的重排序

在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。

- 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
- 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
- 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序。

**源代码->1.编译器优化重排序->2.指令级并行重排序->3.内存系统重排序->最终执行的指令序列。**

上述1术语编译器重排序，2和3属于处理器重排序。这些重排序可能会导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序。

JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。

### 并发编程模型的分类

现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续进行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致。

**处理器操作内存的执行结果**

| 示例项/处理器 | Processor A                                                  | processor B                  |
| ------------- | ------------------------------------------------------------ | ---------------------------- |
| 代码          | a = 1; //A1<br />x = b; //B2                                 | b = 2; //B1<br />y = a; //B2 |
| 运行结果      | 初始状态： a = b = 0<br />处理器允许执行后得到的结果：x = y = 0 |                              |

假设处理器A和处理器B按程序的顺序并行执行内存访问，最终可能得到x = y = 0的结果。

![lpYzr9.png](https://s2.ax1x.com/2019/12/23/lpYzr9.png)

这里处理器A和处理器B可以同时把共享内存写入自己的写缓冲区(A1，B1)，然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓冲区中保存的脏数据刷新到内存中	(A3，B3)。当以这种时许执行时，程序就可以得到x = y =0。

从内存操作实际发生的顺序来看，知道处理器A执行A3来判断自己的写缓存区，写操作A1才算真正的执行了。虽然处理器A执行内存操作的顺序为：A1->A2，但内存操作实际发生的顺序却是A2->A1。此时，处理器A的内存操作顺序被重新排序了。

这里关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写-读操作进行重新排序。

下表时常见处理器允许的重排序类型的列表。

| 处理器/规则 | Load-Load | Load-Store | Store-Store | Store-Load | 数据依赖 |
| ----------- | --------- | ---------- | ----------- | ---------- | -------- |
| SPARC-TSO   | N         | N          | N           | Y          | N        |
| x86         | N         | N          | N           | Y          | N        |
| IA64        | Y         | Y          | Y           | Y          | N        |
| PowerPC     | Y         | Y          | Y           | Y          | N        |

表单元格中的"N"表示处理器不允许两个操作重排序，"Y"表示允许重排序。

为了保成内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类。具体可以详细查询。

### hppens-before简介

在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。

与程序员密切相关的happens-before规则如下：

程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作

监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。

volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。

传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。

注意，两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行。happens-before仅仅要求前一个操作（执行后的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。

