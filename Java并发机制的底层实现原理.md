---
description: The underlying principle of Java concurrency mechanism.
---

# Java并发机制的底层实现原理

Java代码在编译后会编程Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用的并发机制以来与JVM的实现和CPU的指令。

## volatile的应用

在多线程并发编程中synchronized和volatile都扮演着重要的角色，volatile是轻量级的synchronized，它在多处理开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另一个线程能读到这个修改的指。如果volatitle变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为他不会引起线程上下文的切换和调度。

### volatile的定义与实现原理

**volatile定义**：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。

Java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。

**CPU的术语定义**

|    术语    |        英文单词        | 术语描述                                                     |
| :--------: | :--------------------: | ------------------------------------------------------------ |
|  内存屏障  |    menmory barrires    | 一组处理器指令，用于实现对内存操作的顺序限制                 |
|   缓冲行   |       cache line       | CPU高速缓存中可以分配的最小存储单位。处理器填写缓存行时会加载整个缓存行，现代CPU需要执行几百次CPU指令 |
|  原子操作  |   atomic operations    | 不可中断的一个或一系列操作                                   |
| 缓存行填充 |    cacha line fill     | 当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个高速缓存行到适当的缓存(L1，L2，L3的或所有) |
|  缓存命中  |       cache hit        | 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理从缓存中读取操作数，而不是从内存读取 |
|   写命中   |       write hit        | 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存 |
|   写缺失   | write misses the cache | 一个有效的缓存行被写入到不存在的内存区域                     |

**volatile是如何来保证可见性的呢？**

Java代码如下：

```java
instance = new Singleton();
```

转换为汇编代码，如下：

```assembly
0x01a3deld: movb $0×0,0×1104800(%esi);0x01a3de24: lock add1 $0×0,(%esp);
```

有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，Lock前缀的指令在多核处理器下会引发两件事情。

- 将当前处理器缓存行的数据写回到系统内存。
- 这个写回内存的操作会使在其他CPU里缓存了改内存地址的数据无效。

为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2或其他)后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM会向处理器发送一条Lock前缀的指令，将这个变量所在的缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以在多处理器下，为了保证各个处理器的缓存是一致的，就回实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理的缓存行设置成无效状态，当处理器对这个数据进行修改操作时，会重新从系统内存中吧数据读到处理缓存里。

**volatile的两条实现原则**

- Lock前缀指令会引起处理器缓存会写到内存。
- 一个处理器的缓存回写到内存会导致其他处理器的缓存无效。

### volatile的使用优化

著名的Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类LinkedTransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。

LinkedTransferQueue的代码如下：

```java
/*队列中的头部节点*/
private transient final PaddedAtomicReference<QNode> head;
/*队列中的尾部节点*/
private transient final PaddedAtomicReference<QNode> tail;
static final class PaddedAtomicReference <T> extends AtomicReference <T> {
    //使用很多4个字节的引用追加到64字节
    Object P0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe;
    PaddedAtomicReference(T r) {
        super();
    }
}
public class AtomicReference <V> implements java.io.Serializable {
    private volatile V value;
    //省略其他代码
}
```

**追加字节能优化性能**。`LinkedTransferQueue`这个类，它使用一个内部类类型来定义队列的头节点和尾节点，而这个内部类`PaddedAtomicReference`相对于父类`AtomicReference`只做了一件事情，就是将共享变量追加到64字节。有个对象的引用占4个字节，追加了15个占60个字节，再加上父类的value变量共64个字节。

**为什么追加64字节能够提高并发编程的效率呢**？对于目前主流的处理器的L1，L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将他们都读到同一个高速缓存行中，在多处理器下每个处理器都缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的效率。使用追加到64字节的方式来填满高速缓冲区的缓存行，避免头、尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。

**那么是不是在使用volatile变量时都应该追加到64字节呢？**

以下两种场景不应该使用这种方式：

- **缓存行非64字节宽的处理器。**

  **共享变量不会被频繁地写。**

- 

## synchronized的实现原理与应用

在多线程并发编程中`synchronized`一直是元老级的角色，很多人会称呼它为重量级锁。

利用`synchronized`实现同步的基础：Java中的每一个对象都可以作为锁。表现为以下3种形式：

- 对于普通同步方法，锁是当前实例对象。
- 对于静态同步方法，锁是当前类的Class对象。
- 对于同步方法块，锁是`Synchonized`括号里配置的对象。

当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。从JVM规范中可以看到`Synchonized`在JVM里的实现原理，JVM基于进入和退出`Monitor`对象来实现方法同步和代码块同步，但两者的实现细节不一样。具体可以详细查阅JVM规范。

### Java对象头

`synchronized`用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽存储对象头，如果对象是非数组类型，则用2个字款存储对象头。在32位虚拟机中，1字款等于4字节，即32bit。

### 锁的升级与对比

Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。

